{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate rouge_score nltk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T20:30:04.512392Z","iopub.execute_input":"2025-05-01T20:30:04.512907Z","iopub.status.idle":"2025-05-01T20:30:11.755166Z","shell.execute_reply.started":"2025-05-01T20:30:04.512890Z","shell.execute_reply":"2025-05-01T20:30:11.754487Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=fd9239f55694509c331081383502ac476e98ddcfef61c0fb453a129f33bfd234\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: fsspec, rouge_score, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n!pip install transformers datasets evaluate rouge_score peft -q\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nimport evaluate\n\n\nds = load_dataset(\"akemiH/NoteChat\", split=\"train\")\nsmall = ds.shuffle(seed=42).select(range(13000))\ntrain_ds = small.select(range(10000))\ntest_ds  = small.select(range(10000, 13000))\n\n\nmodel_name = \"LGAI-EXAONE/EXAONE-Deep-2.4B\"\ntokenizer  = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\neos = tokenizer.eos_token or tokenizer.sep_token or \"<|endoftext|>\"\n\ndef format_example(ex):\n    return {\"full_text\": ex[\"conversation\"] + eos + ex[\"data\"] + eos}\n\ntrain_ds = train_ds.map(format_example, remove_columns=train_ds.column_names)\ntest_ds  = test_ds.map(format_example,  remove_columns=test_ds.column_names)\n\ndef tokenize_fn(examples):\n    toks = tokenizer(\n        examples[\"full_text\"],\n        max_length=256,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    toks[\"labels\"] = toks[\"input_ids\"].copy()\n    return toks\n\ntrain_ds = train_ds.map(tokenize_fn, batched=True)\ntest_ds  = test_ds.map(tokenize_fn,  batched=True)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nmodel.gradient_checkpointing_enable()\n\nlora_cfg = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"c_attn\", \"c_proj\"],\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\nmodel = get_peft_model(model, lora_cfg)\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n\nrouge = evaluate.load(\"rouge\")\nbleu  = evaluate.load(\"bleu\")\n\nimport bert_score\n\ndef compute_metrics(eval_preds):\n    pred_ids, label_ids = eval_preds\n    preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labs  = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n    \n    responses, references = [], []\n    for p, l in zip(preds, labs):\n        rp = p.split(eos, 1)\n        lp = l.split(eos, 1)\n        responses.append(rp[1].strip() if len(rp)>1 else p)\n        references.append(lp[1].strip() if len(lp)>1 else l)\n    \n\n    rouge_res = rouge.compute(predictions=responses, references=references)\n    \n\n    bleu_res  = bleu.compute(\n        predictions=[r.split() for r in responses],\n        references=[[ref.split()] for ref in references]\n    )\n    \n\n    bert_score_res = bert_score.score(responses, references, lang='en')\n  \n    bert_f1 = bert_score_res[2].mean().item()\n\n    return {\n        \"rouge1\": round(rouge_res[\"rouge1\"].mid.fmeasure * 100, 2),\n        \"rougeL\": round(rouge_res[\"rougeL\"].mid.fmeasure * 100, 2),\n        \"bleu\": round(bleu_res[\"bleu\"] * 100, 2),\n        \"bert_f1\": round(bert_f1 * 100, 2),\n    }\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./exaone_notechat_lora_fp16\",\n    per_device_train_batch_size=10,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=1,\n    eval_accumulation_steps=1,\n    num_train_epochs=3,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_steps=20,\n    save_steps=500,\n    save_total_limit=1,\n    fp16=True,\n    report_to=\"none\"\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T20:30:11.756816Z","iopub.execute_input":"2025-05-01T20:30:11.757048Z","iopub.status.idle":"2025-05-01T20:38:45.874856Z","shell.execute_reply.started":"2025-05-01T20:30:11.757029Z","shell.execute_reply":"2025-05-01T20:38:45.874239Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-05-01 20:31:39.441754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746131499.714389      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746131499.787763      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/542 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769d86fdea054dc3a484993f4e21b00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-5e7cb295b9cff0bf.parquet:   0%|          | 0.00/70.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93368806d162466cb07789c12eeece18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/112165 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e2124e0bdb438f84125157346a1257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/70.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df284828f524ab1a2703baead4e0114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5594ddcf282b4f0fa107afed416bd81d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c7e36a44564efab548a7e4f26a4987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0af3248c4945b78392bd9ef95b5a66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/563 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1138a931044a4e9523d2051c526316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6feeb0a79634db090211b1d34441554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0473eee19774fd1b181f45a02c4c5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ffd271ed4c347e9bdb48d0f1f4ca091"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f965b69cc8a465f82d433ba3740e5e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fab554aab024e6abc5f2347567cc3ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_exaone.py:   0%|          | 0.00/9.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"485829c3cd15437598fbb6ae3d66ea7f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-2.4B:\n- configuration_exaone.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_exaone.py:   0%|          | 0.00/63.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecefb350a2b41d89a8e1bb40bd5fcce"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-2.4B:\n- modeling_exaone.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.81G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93bf2b58523545cfb778bb09f796c1fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/223 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e15412b62e043648c5396d88e54aff7"}},"metadata":{}},{"name":"stdout","text":"Trainable parameters:\n  base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.12.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.12.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.13.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.13.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.14.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.14.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.15.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.15.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.16.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.16.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.17.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.17.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.18.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.18.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.19.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.19.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.20.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.20.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.21.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.21.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.22.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.22.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.23.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.23.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.24.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.24.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.25.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.25.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.26.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.26.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.27.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.27.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.28.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.28.mlp.c_proj.lora_B.default.weight\n  base_model.model.transformer.h.29.mlp.c_proj.lora_A.default.weight\n  base_model.model.transformer.h.29.mlp.c_proj.lora_B.default.weight\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4303ec5e59964b2eaa95c6640fb255eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"198e5eee03bb44e6ac45bf4c4e83db8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00fc2ecaf85145d48c97f182078a8c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28bb206ea73846f58efb8ba089ab9d31"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/3396263849.py:119: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 06:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>4.513000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>4.303700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>4.151500</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>3.997300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>3.868800</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>3.771300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>3.757700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>3.631300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>3.608000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.573800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>3.592500</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>3.512600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>3.577800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>3.528600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.595300</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>3.531000</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>3.494100</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>3.450300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"\n!pip install bert-score -q\nimport torch\nfrom tqdm.auto import tqdm\n\nmodel.eval()\ndevice = next(model.parameters()).device\n\npredictions = []\nreferences  = []\n\nfor example in test_ds:\n    # Prepare input_ids (prompt only)\n    input_ids = torch.tensor([example[\"input_ids\"]]).to(device)\n\n    with torch.no_grad():\n        \n        output_ids = model.generate(\n            input_ids,\n            max_new_tokens=128,\n            do_sample=False,\n            pad_token_id=tokenizer.eos_token_id\n        )[0]\n\n   \n    text = tokenizer.decode(output_ids, skip_special_tokens=True)\n    parts = text.split(eos, 1)\n    pred_response = parts[1].strip() if len(parts) > 1 else text\n    predictions.append(pred_response)\n\n\n    full = example[\"full_text\"]\n    ref = full.split(eos, 1)[1].strip()\n    references.append(ref)\n\n\n\nimport evaluate\nfrom bert_score import score as bert_score_fn\n\nrouge = evaluate.load(\"rouge\")\nbleu  = evaluate.load(\"bleu\")\n\ndef compute_metrics(preds, refs):\n    # assert len(preds) == len(refs), \"preds/ref length mismatch\"\n    \n   \n    rouge_res = rouge.compute(predictions=preds, references=refs)\n    \n\n    tokenized_preds = [p.split() for p in preds]\n    tokenized_refs  = [[r.split()] for r in refs]\n    bleu_res = bleu.compute(\n        predictions=tokenized_preds,\n        references=tokenized_refs\n    )\n    \n    P, R, F1 = bert_score_fn(preds, refs, lang=\"en\")\n    bert_p, bert_r, bert_f1 = float(P.mean()), float(R.mean()), float(F1.mean())\n    \n    return {\n        \"rouge1\":      round(rouge_res[\"rouge1\"].mid.fmeasure * 100, 2),\n        \"rougeL\":      round(rouge_res[\"rougeL\"].mid.fmeasure * 100, 2),\n        \"bleu\":        round(bleu_res[\"bleu\"] * 100, 2),\n        \"bert_f1\":     round(bert_f1, 2)\n    }\n\n\n\n\nmetrics = compute_metrics(predictions, references)\nprint( metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:24:14.309638Z","iopub.execute_input":"2025-05-02T11:24:14.310058Z","iopub.status.idle":"2025-05-02T11:24:14.314798Z","shell.execute_reply.started":"2025-05-02T11:24:14.310034Z","shell.execute_reply":"2025-05-02T11:24:14.314013Z"}},"outputs":[{"name":"stdout","text":"{'rouge1': 67.11, 'rougeL': 65.77, 'bleu': 50.31, 'bert_f1':0.69}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:37:44.477802Z","iopub.execute_input":"2025-05-02T10:37:44.478117Z","iopub.status.idle":"2025-05-02T10:37:49.450811Z","shell.execute_reply.started":"2025-05-02T10:37:44.478097Z","shell.execute_reply":"2025-05-02T10:37:49.449721Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install google-generativeai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:38:07.085626Z","iopub.execute_input":"2025-05-02T10:38:07.086014Z","iopub.status.idle":"2025-05-02T10:38:10.172298Z","shell.execute_reply.started":"2025-05-02T10:38:07.085987Z","shell.execute_reply":"2025-05-02T10:38:10.171196Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:40:25.429343Z","iopub.execute_input":"2025-05-02T10:40:25.429626Z","iopub.status.idle":"2025-05-02T10:40:30.260725Z","shell.execute_reply.started":"2025-05-02T10:40:25.429604Z","shell.execute_reply":"2025-05-02T10:40:30.260006Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=f7f3510e0f3981424e61b6857dac38a948970631c0d35105544f68bb6a581cfb\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\ngemini_preds = []\nreferences   = []\n\nfor ex in test_ds:\n    prompt = (\n        \"You are a meidcal assistant chatbot. Using the SOAP principles—\\n\"\n        \"  • Subjective: capture the patient's own history and complaints,\\n\"\n        \"  • Objective: summarize your exam and findings,\\n\"\n        \"  • Assessment: provide your diagnostic impressions,\\n\"\n        \"  • Plan: outline the care plan—\\n\"\n        \"write one coherent medical report that weaves all four elements together in a single narrative.\\n\\n\"\n        \"Based on all the information provided, generate a comprehensive medical report with sections for History of Present Illness, \"\n        \"Medications, and Allergies.\\n\\n \"\n        \"Patient information:\\n\"\n        + ex[\"input\"]\n        + eos\n    )\n\n    chat = client.chats.create(\n        model=\"gemini-2.0-flash-lite\",\n        config=types.GenerateContentConfig(a\n            temperature=0.0,\n            max_output_tokens=256\n        )\n    )\n    resp = chat.send_message(prompt)\n    gemini_preds.append(resp.text.strip())\n\n\n    full = ex[\"input\"] + eos + ex[\"output\"] + eos\n    references.append(full.split(eos, 1)[1].strip())\n\n    time.sleep(2.1)\n\nmetrics = compute_metrics(gemini_preds, references)\nprint( metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:19:12.691187Z","iopub.execute_input":"2025-05-02T11:19:12.691723Z","iopub.status.idle":"2025-05-02T11:19:12.695613Z","shell.execute_reply.started":"2025-05-02T11:19:12.691694Z","shell.execute_reply":"2025-05-02T11:19:12.694888Z"}},"outputs":[{"name":"stdout","text":"{'rouge1': 53.31, 'rougeL':45.56 , 'bleu': 45.31, 'bert_f1': 0.73}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#adsasdasd","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}